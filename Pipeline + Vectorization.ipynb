{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pipeline + Vectorization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7RIJrkXW92U"
      },
      "source": [
        "# **Assignment 6**:  Pipeline & Vectorization\n",
        "##### Emily Daskas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q7PYXWBX7d4",
        "outputId": "4140dcba-9e1e-4124-d3ff-632648b1c26f"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from textblob import TextBlob\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cuH5EEDXBh0"
      },
      "source": [
        "**Document 1:** It’s become a familiar sight for the Chapman community: President Daniele Struppa standing on stage at the Musco Center, addressing a combined audience of university faculty, staff and university supporters.\n",
        "\n",
        "**Document 2:** What was different this year —as has been the case for most events this year —was that everyone in the audience was viewing the address from home.\n",
        "\n",
        "\n",
        "\n",
        "*In all the 6 problems below, apply ‘List Comprehension’ and ‘Lambda’ functions of Python language to write your code.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ootoCjIXbg-S"
      },
      "source": [
        "document_1 = \"It's become a familiar sight for the Chapman community: President Daniele Struppa standing on stage at the Musco Center, addressing a combined audience of university faculty, staff and university supporters.\"\n",
        "document_2 = \"What was different this year -as has been the case for most events this year -was that everyone in the audience was viewing the address from home.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtR1olVJcVX5"
      },
      "source": [
        "df = pd.DataFrame({'document': [document_1, document_2]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9fxC6gYXPi7"
      },
      "source": [
        "**1.  Clean both the documents by removing all punctuation characters from them.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAetYbavYgeH"
      },
      "source": [
        "def remove_punctuation(txt):\n",
        "  return \"\".join([c for c in txt if c not in string.punctuation])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "baJcTTZOemsE",
        "outputId": "f519be9c-c670-4c71-994b-8beb5929e17d"
      },
      "source": [
        "df['cleaned'] = df['document'].apply(lambda x: remove_punctuation(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's become a familiar sight for the Chapman c...</td>\n",
              "      <td>Its become a familiar sight for the Chapman co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What was different this year -as has been the ...</td>\n",
              "      <td>What was different this year as has been the c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document                                            cleaned\n",
              "0  It's become a familiar sight for the Chapman c...  Its become a familiar sight for the Chapman co...\n",
              "1  What was different this year -as has been the ...  What was different this year as has been the c..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W46EkTcVXWps"
      },
      "source": [
        "**2. Tokenization the words of both documents using Regular Expressions.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SVrLFIJi7jO"
      },
      "source": [
        "def tokenize(txt):\n",
        "  return re.split('\\W+', txt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "bPLA3tBRiXbI",
        "outputId": "f930884f-9983-4986-91a7-8b0fef666840"
      },
      "source": [
        "df['tokenized'] = df['cleaned'].apply(lambda x: tokenize(x.lower()))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's become a familiar sight for the Chapman c...</td>\n",
              "      <td>Its become a familiar sight for the Chapman co...</td>\n",
              "      <td>[its, become, a, familiar, sight, for, the, ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What was different this year -as has been the ...</td>\n",
              "      <td>What was different this year as has been the c...</td>\n",
              "      <td>[what, was, different, this, year, as, has, be...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document  ...                                          tokenized\n",
              "0  It's become a familiar sight for the Chapman c...  ...  [its, become, a, familiar, sight, for, the, ch...\n",
              "1  What was different this year -as has been the ...  ...  [what, was, different, this, year, as, has, be...\n",
              "\n",
              "[2 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3z7xavBXaX7"
      },
      "source": [
        "**3. Download all the English language stop words from NLTK library.  Remove stop words from both documents.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvyhsK9RjORS"
      },
      "source": [
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op2pwFRgjtVG"
      },
      "source": [
        "def remove_stopwords(txt_tokenized):\n",
        "  return [word for word in txt_tokenized if word not in stopwords]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "4xCs90NEj73J",
        "outputId": "0ccd8d46-3b00-4841-df91-e5a92670f7aa"
      },
      "source": [
        "df['no_sw'] = df['tokenized'].apply(lambda x: remove_stopwords(x))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>no_sw</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's become a familiar sight for the Chapman c...</td>\n",
              "      <td>Its become a familiar sight for the Chapman co...</td>\n",
              "      <td>[its, become, a, familiar, sight, for, the, ch...</td>\n",
              "      <td>[become, familiar, sight, chapman, community, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What was different this year -as has been the ...</td>\n",
              "      <td>What was different this year as has been the c...</td>\n",
              "      <td>[what, was, different, this, year, as, has, be...</td>\n",
              "      <td>[different, year, case, events, year, everyone...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document  ...                                              no_sw\n",
              "0  It's become a familiar sight for the Chapman c...  ...  [become, familiar, sight, chapman, community, ...\n",
              "1  What was different this year -as has been the ...  ...  [different, year, case, events, year, everyone...\n",
              "\n",
              "[2 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foBanngUXh0m"
      },
      "source": [
        "**4. Replace the words of both documents with their stems.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INN_GD2PkulR"
      },
      "source": [
        "ps = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97698TFXkVdP"
      },
      "source": [
        "def replace_with_stems(txt_tokenized):\n",
        "  return [ps.stem(word) for word in txt_tokenized]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "pM5w3UEzlAMT",
        "outputId": "8f65a87d-4338-4ef9-c433-00c6b5d826d0"
      },
      "source": [
        "df['stemmed'] = df['no_sw'].apply(lambda x: replace_with_stems(x))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>no_sw</th>\n",
              "      <th>stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's become a familiar sight for the Chapman c...</td>\n",
              "      <td>Its become a familiar sight for the Chapman co...</td>\n",
              "      <td>[its, become, a, familiar, sight, for, the, ch...</td>\n",
              "      <td>[become, familiar, sight, chapman, community, ...</td>\n",
              "      <td>[becom, familiar, sight, chapman, commun, pres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What was different this year -as has been the ...</td>\n",
              "      <td>What was different this year as has been the c...</td>\n",
              "      <td>[what, was, different, this, year, as, has, be...</td>\n",
              "      <td>[different, year, case, events, year, everyone...</td>\n",
              "      <td>[differ, year, case, event, year, everyon, aud...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document  ...                                            stemmed\n",
              "0  It's become a familiar sight for the Chapman c...  ...  [becom, familiar, sight, chapman, commun, pres...\n",
              "1  What was different this year -as has been the ...  ...  [differ, year, case, event, year, everyon, aud...\n",
              "\n",
              "[2 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kasATOQ9Xrhx"
      },
      "source": [
        "**5. Using the Count Vectorizer available in the Scikit-Learn library create a vector for both documents.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg9a3rpBlas-",
        "outputId": "054981cd-6a10-4652-e013-2c5c1b418e94"
      },
      "source": [
        "cv = CountVectorizer()\n",
        "X = cv.fit(df['cleaned'])\n",
        "print(cv.get_feature_names())\n",
        "print(X.vocabulary_)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['address', 'addressing', 'and', 'as', 'at', 'audience', 'become', 'been', 'case', 'center', 'chapman', 'combined', 'community', 'daniele', 'different', 'events', 'everyone', 'faculty', 'familiar', 'for', 'from', 'has', 'home', 'in', 'its', 'most', 'musco', 'of', 'on', 'president', 'sight', 'staff', 'stage', 'standing', 'struppa', 'supporters', 'that', 'the', 'this', 'university', 'viewing', 'was', 'what', 'year']\n",
            "{'its': 24, 'become': 6, 'familiar': 18, 'sight': 30, 'for': 19, 'the': 37, 'chapman': 10, 'community': 12, 'president': 29, 'daniele': 13, 'struppa': 34, 'standing': 33, 'on': 28, 'stage': 32, 'at': 4, 'musco': 26, 'center': 9, 'addressing': 1, 'combined': 11, 'audience': 5, 'of': 27, 'university': 39, 'faculty': 17, 'staff': 31, 'and': 2, 'supporters': 35, 'what': 42, 'was': 41, 'different': 14, 'this': 38, 'year': 43, 'as': 3, 'has': 21, 'been': 7, 'case': 8, 'most': 25, 'events': 15, 'that': 36, 'everyone': 16, 'in': 23, 'viewing': 40, 'address': 0, 'from': 20, 'home': 22}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La3BgG1FoKkF",
        "outputId": "b484d52d-95b6-4f09-8ab3-d38279d1ff78"
      },
      "source": [
        "X = cv.transform(df['cleaned'])\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 1)\t1\n",
            "  (0, 2)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 5)\t1\n",
            "  (0, 6)\t1\n",
            "  (0, 9)\t1\n",
            "  (0, 10)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 13)\t1\n",
            "  (0, 17)\t1\n",
            "  (0, 18)\t1\n",
            "  (0, 19)\t1\n",
            "  (0, 24)\t1\n",
            "  (0, 26)\t1\n",
            "  (0, 27)\t1\n",
            "  (0, 28)\t1\n",
            "  (0, 29)\t1\n",
            "  (0, 30)\t1\n",
            "  (0, 31)\t1\n",
            "  (0, 32)\t1\n",
            "  (0, 33)\t1\n",
            "  (0, 34)\t1\n",
            "  (0, 35)\t1\n",
            "  (0, 37)\t2\n",
            "  (0, 39)\t2\n",
            "  (1, 0)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 5)\t1\n",
            "  (1, 7)\t1\n",
            "  (1, 8)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 15)\t1\n",
            "  (1, 16)\t1\n",
            "  (1, 19)\t1\n",
            "  (1, 20)\t1\n",
            "  (1, 21)\t1\n",
            "  (1, 22)\t1\n",
            "  (1, 23)\t1\n",
            "  (1, 25)\t1\n",
            "  (1, 36)\t1\n",
            "  (1, 37)\t3\n",
            "  (1, 38)\t2\n",
            "  (1, 40)\t1\n",
            "  (1, 41)\t3\n",
            "  (1, 42)\t1\n",
            "  (1, 43)\t2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "X1Vlh1ymm26L",
        "outputId": "55349c91-555b-4187-ae55-5ee310027f21"
      },
      "source": [
        "pd.DataFrame(X.toarray(), columns = cv.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>address</th>\n",
              "      <th>addressing</th>\n",
              "      <th>and</th>\n",
              "      <th>as</th>\n",
              "      <th>at</th>\n",
              "      <th>audience</th>\n",
              "      <th>become</th>\n",
              "      <th>been</th>\n",
              "      <th>case</th>\n",
              "      <th>center</th>\n",
              "      <th>chapman</th>\n",
              "      <th>combined</th>\n",
              "      <th>community</th>\n",
              "      <th>daniele</th>\n",
              "      <th>different</th>\n",
              "      <th>events</th>\n",
              "      <th>everyone</th>\n",
              "      <th>faculty</th>\n",
              "      <th>familiar</th>\n",
              "      <th>for</th>\n",
              "      <th>from</th>\n",
              "      <th>has</th>\n",
              "      <th>home</th>\n",
              "      <th>in</th>\n",
              "      <th>its</th>\n",
              "      <th>most</th>\n",
              "      <th>musco</th>\n",
              "      <th>of</th>\n",
              "      <th>on</th>\n",
              "      <th>president</th>\n",
              "      <th>sight</th>\n",
              "      <th>staff</th>\n",
              "      <th>stage</th>\n",
              "      <th>standing</th>\n",
              "      <th>struppa</th>\n",
              "      <th>supporters</th>\n",
              "      <th>that</th>\n",
              "      <th>the</th>\n",
              "      <th>this</th>\n",
              "      <th>university</th>\n",
              "      <th>viewing</th>\n",
              "      <th>was</th>\n",
              "      <th>what</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   address  addressing  and  as  at  ...  university  viewing  was  what  year\n",
              "0        0           1    1   0   1  ...           2        0    0     0     0\n",
              "1        1           0    0   1   0  ...           0        1    3     1     2\n",
              "\n",
              "[2 rows x 44 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqZvLEvzX01A"
      },
      "source": [
        "**6. Using the Count Vectorizer available in the Scikit-Learn library create a bi-gram and tri-gram vectors for both documents.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWQKZ7I1qqT_"
      },
      "source": [
        "def clean_text_ngram(txt):\n",
        " txt = remove_punctuation(txt)\n",
        " tokens = tokenize(txt)\n",
        " return \" \".join([ps.stem(word) for word in tokens if word not in stopwords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "RKKe04wLrTpg",
        "outputId": "342ec048-09de-4a61-8329-7160b7590406"
      },
      "source": [
        "df['clean_ngram'] = df['document'].apply(lambda x: clean_text_ngram(x))\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>no_sw</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>clean_ngram</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's become a familiar sight for the Chapman c...</td>\n",
              "      <td>Its become a familiar sight for the Chapman co...</td>\n",
              "      <td>[its, become, a, familiar, sight, for, the, ch...</td>\n",
              "      <td>[become, familiar, sight, chapman, community, ...</td>\n",
              "      <td>[becom, familiar, sight, chapman, commun, pres...</td>\n",
              "      <td>it becom familiar sight chapman commun presid ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What was different this year -as has been the ...</td>\n",
              "      <td>What was different this year as has been the c...</td>\n",
              "      <td>[what, was, different, this, year, as, has, be...</td>\n",
              "      <td>[different, year, case, events, year, everyone...</td>\n",
              "      <td>[differ, year, case, event, year, everyon, aud...</td>\n",
              "      <td>what differ year case event year everyon audie...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            document  ...                                        clean_ngram\n",
              "0  It's become a familiar sight for the Chapman c...  ...  it becom familiar sight chapman commun presid ...\n",
              "1  What was different this year -as has been the ...  ...  what differ year case event year everyon audie...\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "RSrDp67gr3w8",
        "outputId": "c180da14-cfcc-48b1-a478-399fc0ed5657"
      },
      "source": [
        "cv = CountVectorizer(ngram_range=(2, 3))\n",
        "X = cv.fit_transform(df['clean_ngram'])\n",
        "df = pd.DataFrame(X.toarray(), columns = cv.get_feature_names())\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>address combin</th>\n",
              "      <th>address combin audienc</th>\n",
              "      <th>address home</th>\n",
              "      <th>audienc univers</th>\n",
              "      <th>audienc univers faculti</th>\n",
              "      <th>audienc view</th>\n",
              "      <th>audienc view address</th>\n",
              "      <th>becom familiar</th>\n",
              "      <th>becom familiar sight</th>\n",
              "      <th>case event</th>\n",
              "      <th>case event year</th>\n",
              "      <th>center address</th>\n",
              "      <th>center address combin</th>\n",
              "      <th>chapman commun</th>\n",
              "      <th>chapman commun presid</th>\n",
              "      <th>combin audienc</th>\n",
              "      <th>combin audienc univers</th>\n",
              "      <th>commun presid</th>\n",
              "      <th>commun presid daniel</th>\n",
              "      <th>daniel struppa</th>\n",
              "      <th>daniel struppa stand</th>\n",
              "      <th>differ year</th>\n",
              "      <th>differ year case</th>\n",
              "      <th>event year</th>\n",
              "      <th>event year everyon</th>\n",
              "      <th>everyon audienc</th>\n",
              "      <th>everyon audienc view</th>\n",
              "      <th>faculti staff</th>\n",
              "      <th>faculti staff univers</th>\n",
              "      <th>familiar sight</th>\n",
              "      <th>familiar sight chapman</th>\n",
              "      <th>it becom</th>\n",
              "      <th>it becom familiar</th>\n",
              "      <th>musco center</th>\n",
              "      <th>musco center address</th>\n",
              "      <th>presid daniel</th>\n",
              "      <th>presid daniel struppa</th>\n",
              "      <th>sight chapman</th>\n",
              "      <th>sight chapman commun</th>\n",
              "      <th>staff univers</th>\n",
              "      <th>staff univers support</th>\n",
              "      <th>stage musco</th>\n",
              "      <th>stage musco center</th>\n",
              "      <th>stand stage</th>\n",
              "      <th>stand stage musco</th>\n",
              "      <th>struppa stand</th>\n",
              "      <th>struppa stand stage</th>\n",
              "      <th>univers faculti</th>\n",
              "      <th>univers faculti staff</th>\n",
              "      <th>univers support</th>\n",
              "      <th>view address</th>\n",
              "      <th>view address home</th>\n",
              "      <th>what differ</th>\n",
              "      <th>what differ year</th>\n",
              "      <th>year case</th>\n",
              "      <th>year case event</th>\n",
              "      <th>year everyon</th>\n",
              "      <th>year everyon audienc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   address combin  address combin audienc  ...  year everyon  year everyon audienc\n",
              "0               1                       1  ...             0                     0\n",
              "1               0                       0  ...             1                     1\n",
              "\n",
              "[2 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}